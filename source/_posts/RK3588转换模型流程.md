---
title: RK3588转换模型流程
typora-root-url: RK3588转换模型流程
date: 2024-10-30 00:47:17
category:
tags:
---

## 简介

本文章介绍了怎么在搭载了RK3588芯片的主机下使用YOLO系列模型，需要下载的必要资源库[ultralytics](https://github.com/ultralytics/ultralytics)，[rknn_model_zoo](https://github.com/airockchip/rknn_model_zoo)，[rknn-toolkit2](https://github.com/airockchip/rknn-toolkit2)，具体的流程为：

![process](process.png)

> 本例程建立在你了解Python虚拟环境的条件下

## 作者实验环境

* 瑞芯微主板环境：众云世纪 RK3588 高性能人工智能主板 ZYSJ-2288A
* pt --> onnx 环境：x86 win11
* onnx --> rknn环境：x86 ubuntu22.04
* rknn_model_zoo：v2.2.0
* rknn-toolkit2：v2.2.0

## 必要资源（先下好！！！先下好！！！）

直接下载最新版本即可，另外，rknn-toolkit SDK，也就是第一代[rknn-toolkit]( https://github.com/airockchip/rknn-toolkit) SDK，只支持这些芯片：**RK1808/RV1109/RV1126/RK3399Pro**，其他的芯片型号请继续使用rknn-toolkit2。

* [ultralytics](https://github.com/ultralytics/ultralytics)（非必选，但是如果后续换成自己改的模型还是需要用到）
* [rknn_model_zoo](https://github.com/airockchip/rknn_model_zoo)
* [rknn-toolkit2](https://github.com/airockchip/rknn-toolkit2)

如果你没有x86 Linux主机，请使用虚拟机，推荐使用Ubuntu 22.04版本。

## pt模型 --> onnx模型

> 说明：运行环境为x86 windows系统或linux系统均可，全程不需要配置显卡驱动；选择转换为onnx是因为onnxruntime在转换pt模型的过程中，会去除对硬件计算冗余的节点，并且针对不同硬件（CPU、GPU）进行子图优化，总而言之就是进行了硬件加速。

使用conda或者python自带的venv功能创建一个`Python>=3.8`，`PyTorch>=1.8`的环境，<u>**激活环境后**</u>使用以下命令安装ultralytics库：

```shell
pip install ultralytics
pip install onnxruntime # 因为我们全程不会用到GPU，因此直接下载CPU版本即可，如果有需要执行前往onnx的官方文档查询怎么正确下载
```

找到你的模型目录，**<u>在你创建的虚拟环境下</u>**执行以下命令，即可将你训练好的模型转化成onnx格式：

```shell
yolo export model=yourModel.pt format=onnx
```

详细参数参考ultralytics官方[Export命令参数文档](https://docs.ultralytics.com/modes/export/#arguments)，主要调整的参数为half（采用16位半精度的浮点数记录模型参数）和int8（采用8位整数记录模型参数），都是用于减少模型所需算力的。

## onnx模型 --> rknn模型

> 说明：切记转换模型要在x86 Linux系统中进行，因此我们需要再配置一次环境，使用瑞芯微官方的sdk——rknn-toolkit2进行模型转换；转换成rknn是为了充分利用瑞芯微的芯片上NPU的性能，量化某些参数来适配芯片的计算需求。

### 安装rknn-toolkit2 SDK

在**<u>x86 Linux系统</u>**上使用conda或者python自带的venv功能创建一个`Python==3.8`(官方推荐版本)，**<u>激活环境后</u>**，进入rknn-toolkit2 目录目录，根据python版本配置环境，输入以下指令：

```shell
pip install -r packages/requirements_cpxx.txt
# 此处的cpxx中xx指的是Python的版本，比如说3.8就安装cp38，3.10就安装cp310

pip install packages/rknn_toolkit2--x.x.x-cpxx-cpxx-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
# 此处cpxx和上面一样，rknn_toolkit2--x.x.x指的是rknn-toolkit2 SDK的版本号，安装的时候输入packages,rknn后，按Tab键即可自动补全
```

### 使用rknn_model_zoo中的样例将模型转化成rknn格式

进入`rknn_model_zoo/examples/yolov8/python`目录，运行`convert.py`文件，命令行代码如下：

```shell
# 进入 rknn_model_zoo/examples/yolov8/python 目录
cd Projects/rknn_model_zoo/examples/yolov8/python

# 运行 convert.py 脚本，将原始的 ONNX 模型转成 RKNN 模型
# 用法: python convert.py model_path [rk3566|rk3588|rk3562] [i8/fp] [output_path]
# 第二个参数是指设备的信息，第三个参数是指转换模型时参数的数据类型，默认是i8，即int8，更多细节请阅读目录下的README.md
python convert.py ../model/yolov5s_relu.onnx rk3588 i8 ../model/yolov5s_relu.rknn
```

## 部署模型

回到rk3588主机，配置环境，主要是和c++相关用于编译rknn_model_zoo中的一些样例和后期编写代码时调用rknn-toolkit2中的一些接口：

```shell
sudo apt install gcc cmake # gcc就是c++的源码库，cmake则是辅助gcc编译的工具
```

复制一份rknn_model_zoo，进入rknn_model_zoo目录，执行里面的`build-linux.sh`脚本，即可编译好对应模型使用的二进制脚本，具体命令如下：

```shell
chmod +x build-linux.sh
./build-linux.sh -t rk3588 -a aarch64 -d yolov8
```

> 该脚本的参数示意如下：
>
> ```shell
> ./build-linux.sh -t 芯片类型 -a [aarch64/armhf] -d demo名字 [-b <build_type>] [-m]
> ```
>
> 后两个参数一般用不到，`-b`用于设置编译模式模式，接debug表示展示编译信息，接release表示会对编译进行优化，不显示调试信息，`-m`用于在调试过程中展示内存错误。
>
> 该脚本仅支持编译以下的神经网络模型，其他的需要自己写C++文件：
>
> ```shell
> yolov10
> mobilesam
> LPRNet
> yolo_world
> yolov6
> clip
> yolox
> deeplabv3
> whisper
> yamnet
> yolov5_seg
> yolov8_seg
> yolov5
> yolov8_obb
> mobilenet
> RetinaFace
> yolov7
> resnet
> PPOCR-Rec
> PPOCR-Det
> PPOCR-System
> ppyoloe
> lite_transformer
> ppseg
> yolov8
> yolov8_pose
> wav2vec2
> rv1106_rv1103 only support: mobilenet and yolov5/6/7/8/x
> ```

编译之后，只要进行到百分之百就是编译成功，编译成功的文件会存储在`./build`目录下类似于`build_rknn_yoloxx_demo_rkxxxx_linux_Arch_MakeType`的目录下面，目录名字和你编译时使用的参数有关，进入该目录，类似`rknn_yoloxx_demo`的无后缀文件就是可以直接用于视觉识别的二进制可执行文件，在正式运行前，还需做一些准备工作：

```shell
cd ./build/build_rknn_yoloxx_demo_rkxxxx_linux_Arch_MakeType
# 移动到编译好的目录
cp -r ../../examples/yolov8/model ./
# 将样例中的model目录移动到当前目录下，并且将你训练好的模型、分类文件（classes.txt）放进./model目录中（**这一步需要你自己额外操作**）
./rknn_yolov8_demo yourModel.rknn yourPhoto.jpg
# 这一步会生成一个识别后的图片，名字叫out.png
```

下面展示一下我识别的长颈鹿：

![val1](val1.jpg)

![out](out.png)



参考资料：

- [yolov5训练并生成rknn模型以及3588平台部署](https://blog.csdn.net/m0_51714298/article/details/125916417)
- [yolov5训练pt模型并转换为rknn模型，部署在RK3588开发板上——从训练到部署全过程](https://blog.csdn.net/m0_57315535/article/details/128250096)

* [01_Rockchip_RKNPU_Quick_Start_RKNN_SDK_V2.2.0_CN.pdf](https://github.com/airockchip/rknn-toolkit2/blob/master/doc/01_Rockchip_RKNPU_Quick_Start_RKNN_SDK_V2.2.0_CN.pdf)
